{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#   Ignore warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"rS6ftfIhV7k-","execution":{"iopub.status.busy":"2022-01-18T12:21:10.501707Z","iopub.execute_input":"2022-01-18T12:21:10.502362Z","iopub.status.idle":"2022-01-18T12:21:10.507494Z","shell.execute_reply.started":"2022-01-18T12:21:10.502326Z","shell.execute_reply":"2022-01-18T12:21:10.506680Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"base_path = './'\nimport os\nos.path.isdir(base_path)","metadata":{"id":"zmDqjy4XXSR8","execution":{"iopub.status.busy":"2022-01-18T12:21:10.509080Z","iopub.execute_input":"2022-01-18T12:21:10.509908Z","iopub.status.idle":"2022-01-18T12:21:10.517820Z","shell.execute_reply.started":"2022-01-18T12:21:10.509869Z","shell.execute_reply":"2022-01-18T12:21:10.516548Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten, Conv2D, Conv2DTranspose, Input, Reshape, Embedding, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.layers import Concatenate, LeakyReLU\nfrom keras.datasets import fashion_mnist\nfrom tqdm import tqdm_notebook","metadata":{"id":"fjfWnbpZnpzH","execution":{"iopub.status.busy":"2022-01-18T12:21:10.519644Z","iopub.execute_input":"2022-01-18T12:21:10.520366Z","iopub.status.idle":"2022-01-18T12:21:10.527324Z","shell.execute_reply.started":"2022-01-18T12:21:10.520329Z","shell.execute_reply":"2022-01-18T12:21:10.526559Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#   Define Generator\ndef generator(noise_dims, n_class):\n    input_label = Input(shape = (1,))\n    embed_label = Embedding(n_class, 50)(input_label)\n    label_dense = Dense(49)(embed_label)\n    label_img = Reshape((7, 7, 1))(label_dense)\n\n    input_noise = Input(shape = (noise_dims, ))\n    n_nodes = 7*7*128\n    gen = Dense(n_nodes)(input_noise)\n    gen = LeakyReLU(alpha = .2)(gen)\n    gen = Reshape((7, 7, 128))(gen)\n\n    #   Concatenate gen with label_embed\n    merge = Concatenate()([gen, label_img])\n    # Upsample to 14x14x64\n    gen = Conv2DTranspose(64, (4, 4), strides = 2, padding = 'same')(merge)\n    gen = LeakyReLU(alpha = .2)(gen)\n    # Upsample to 28x28x32\n    gen = Conv2DTranspose(32, (4, 4), strides = 2, padding = 'same')(gen)\n    gen = LeakyReLU(alpha = .2)(gen)\n\n    #   Conv to 28x28x3\n    fake_imgs = Conv2D(1, (7, 7), padding = 'same', activation = 'tanh')(gen)\n\n    #   Define model\n    gen_model = Model(inputs = [input_noise, input_label], outputs = fake_imgs)\n    return gen_model","metadata":{"id":"iK8_eWtYncNh","execution":{"iopub.status.busy":"2022-01-18T12:21:10.528616Z","iopub.execute_input":"2022-01-18T12:21:10.529407Z","iopub.status.idle":"2022-01-18T12:21:10.539353Z","shell.execute_reply.started":"2022-01-18T12:21:10.529373Z","shell.execute_reply":"2022-01-18T12:21:10.538577Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def discriminator(input_shape, n_class):\n    input_label = Input(shape = (1,))\n    embed_label = Embedding(n_class, 50)(input_label)\n    label_dense = Dense(input_shape[0] * input_shape[1])(embed_label)\n    label_img = Reshape(input_shape)(label_dense)\n\n    input_img = Input(shape = input_shape)\n    #   Concate input_img and label_img\n    merge = Concatenate()([input_img, label_img])\n    #   Downsample\n    #   14x14x64\n    discr = Conv2D(64, (3, 3), strides = 2, padding = 'same')(merge)\n    discr = LeakyReLU(alpha = .2)(discr)\n    #   7x7x128\n    discr = Conv2D(128, (3, 3), strides = 2, padding = 'same')(merge)\n    discr = LeakyReLU(alpha = .2)(discr)\n    #   Flatten feature maps\n    discr = Flatten()(discr)\n    discr = Dropout(0.4)(discr)\n    out_layer = Dense(1, activation = 'sigmoid')(discr)\n    #   Define Discriminator model\n    discr_model = Model(inputs = [input_img, input_label], outputs = out_layer)\n    discr_model.compile(optimizer = Adam(learning_rate = 2e-4, beta_1 = 0.5), loss = 'binary_crossentropy', metrics = ['acc'])\n    return discr_model","metadata":{"id":"ZOK93EVa1stq","execution":{"iopub.status.busy":"2022-01-18T12:21:10.541453Z","iopub.execute_input":"2022-01-18T12:21:10.541999Z","iopub.status.idle":"2022-01-18T12:21:10.551829Z","shell.execute_reply.started":"2022-01-18T12:21:10.541964Z","shell.execute_reply":"2022-01-18T12:21:10.551131Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(X_data, labels):\n    X = np.expand_dims(X_data, -1)\n    X_trai = X.astype('float32')\n    X_processed = (X/255.0) * 2 - 1\n    return [X_processed, labels]","metadata":{"id":"sp0X1dvcCS_Q","execution":{"iopub.status.busy":"2022-01-18T12:21:10.552646Z","iopub.execute_input":"2022-01-18T12:21:10.552861Z","iopub.status.idle":"2022-01-18T12:21:10.563389Z","shell.execute_reply.started":"2022-01-18T12:21:10.552838Z","shell.execute_reply":"2022-01-18T12:21:10.562661Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def define_gan(gen_model, discr_model):\n    #   Freeze Discriminator weights when training generator\n    discr_model.trainable = False\n    #   Get noises and labels input from generator model\n    gen_noise, gen_label = gen_model.input\n    #   Get image output from generator model\n    gen_out = gen_model.output\n    #   Connect image output and label input from generator model as inputs to discriminator model\n    discr_out = discr_model([gen_out, gen_label]) \n    #   Define GAN model as taking noise and label and outputinga classification\n    C_gan = Model(inputs = [gen_noise, gen_label], outputs = discr_out)\n    opt = Adam(learning_rate = 2e-4, beta_1 = 0.5)\n    C_gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['acc'])\n    return C_gan","metadata":{"id":"EG5M4zFrDIsq","execution":{"iopub.status.busy":"2022-01-18T12:21:10.564891Z","iopub.execute_input":"2022-01-18T12:21:10.565223Z","iopub.status.idle":"2022-01-18T12:21:10.572876Z","shell.execute_reply.started":"2022-01-18T12:21:10.565184Z","shell.execute_reply":"2022-01-18T12:21:10.572134Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(dataset, n_sample):\n    #   Split into images and labels\n    images, labels = dataset\n    #   Choose random instances\n    index = np.random.randint(0, images.shape[0], n_sample)\n    #   Select images and labels from random above instances\n    X_real, labels = images[index], labels[index]\n    #   Create class labels\n    Y1 = np.ones((n_sample, 1))\n    return X_real, labels, Y1","metadata":{"id":"ud_4gm5MF7gr","execution":{"iopub.status.busy":"2022-01-18T12:21:10.574446Z","iopub.execute_input":"2022-01-18T12:21:10.574767Z","iopub.status.idle":"2022-01-18T12:21:10.581547Z","shell.execute_reply.started":"2022-01-18T12:21:10.574735Z","shell.execute_reply":"2022-01-18T12:21:10.580895Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def generate_latent_point(latent_dims, n_sample, n_class):\n    noise = np.random.randn(n_sample, latent_dims)\n    labels = np.random.randint(0, n_class, (n_sample, 1))\n    return noise, labels","metadata":{"id":"qNh-jgaXKmDe","execution":{"iopub.status.busy":"2022-01-18T12:21:10.582406Z","iopub.execute_input":"2022-01-18T12:21:10.583286Z","iopub.status.idle":"2022-01-18T12:21:10.591928Z","shell.execute_reply.started":"2022-01-18T12:21:10.583250Z","shell.execute_reply":"2022-01-18T12:21:10.591384Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(gen_model, latent_dims, n_sample, n_class):\n    noise, labels = generate_latent_point(latent_dims, n_sample, n_class)\n    Y0 = np.zeros((n_sample, 1))\n    X_fake = gen_model.predict_on_batch([noise, labels])\n    return X_fake, labels, Y0","metadata":{"id":"WQlqc7_xPj1K","execution":{"iopub.status.busy":"2022-01-18T12:21:10.619961Z","iopub.execute_input":"2022-01-18T12:21:10.620136Z","iopub.status.idle":"2022-01-18T12:21:10.626815Z","shell.execute_reply.started":"2022-01-18T12:21:10.620115Z","shell.execute_reply":"2022-01-18T12:21:10.626143Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def plot_result(images):\n    h, w, c = images.shape[1:]\n    grid_size = int(np.sqrt(images.shape[0]))\n    images = ((images + 1)/2.)*255.\n    images = images.astype('uint8')\n    images = images.reshape(grid_size, grid_size, h, w, c).transpose(0, 2, 1, 3, 4).reshape(grid_size*h, grid_size*w, c)\n    plt.imshow(images, cmap = 'gray_r')\n    plt.axis('off')\n    plt.show()","metadata":{"id":"CnHU3_m09z6S","execution":{"iopub.status.busy":"2022-01-18T12:21:10.628318Z","iopub.execute_input":"2022-01-18T12:21:10.628704Z","iopub.status.idle":"2022-01-18T12:21:10.635094Z","shell.execute_reply.started":"2022-01-18T12:21:10.628655Z","shell.execute_reply":"2022-01-18T12:21:10.634287Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def train(dataset, C_gan, gen_model, discr_model, latent_dims, n_class, epochs, batch_size, plot_freq, n_sample = 36):\n    iters = dataset[0].shape[0] // batch_size\n    half_batch = batch_size // 2\n    #   Define loss\n    losses = {'D': [], 'G': []}\n\n    #   Create fixed noise latent to evaluate generator model\n    noise_fixed = np.random.normal(-1, 1, (n_sample, latent_dims))\n    desire_labels = np.random.randint(0, n_class, (n_sample, 1))\n    for epoch in tqdm_notebook(range(1, epochs + 1)):\n        if epoch == 1 or epoch % plot_freq == 0:\n            print('-'*30, f'Epoch {epoch}', '-'*30)\n        for i in range(iters):\n            # ======================== Train Discriminator ========================\n            #   Get randomly selected 'real' samples\n            X_real, real_labels, Y1 = generate_real_samples(dataset, half_batch)\n            #   Update discriminator weights by training it with REAL samples\n            D_loss_real = discr_model.train_on_batch([X_real, real_labels], Y1)\n            #   Generate FAKE samples\n            X_fake, fake_labels, Y0 = generate_fake_samples(gen_model, latent_dims, half_batch, n_class)\n            #   Update discriminator weights by training it with FAKE samples\n            D_loss_fake = discr_model.train_on_batch([X_fake, fake_labels], Y0)\n            #   Total discriminator loss\n            losses['D'].append(D_loss_real + D_loss_fake)\n\n            # ======================== Train Generator ========================\n            #   Prepare points in latent space as input of generator\n            noise, labels = generate_latent_point(latent_dims, batch_size, n_class)\n            #   Create real labels for training generator\n            Y_gen_1 = np.ones((batch_size, 1))\n            #   Update generator weights via the discriminator error\n            G_loss = C_gan.train_on_batch([noise, labels], Y_gen_1)\n            losses['G'].append(G_loss)\n        if epoch == 1 or epoch % plot_freq == 0:\n            fake_imgs = gen_model.predict_on_batch([noise_fixed, desire_labels])\n            print(fake_imgs.shape)\n            plot_result(fake_imgs)","metadata":{"id":"FwUnbEfvRkdQ","execution":{"iopub.status.busy":"2022-01-18T12:21:10.636643Z","iopub.execute_input":"2022-01-18T12:21:10.637887Z","iopub.status.idle":"2022-01-18T12:21:10.650402Z","shell.execute_reply.started":"2022-01-18T12:21:10.637846Z","shell.execute_reply":"2022-01-18T12:21:10.649743Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"(X_train, Y_train), (_, _) = fashion_mnist.load_data()\ndataset = preprocess_data(X_train, Y_train)\nnoise_dims = 100\nn_class = 10\ngen_model = generator(noise_dims, n_class)\ndiscr_model = discriminator((28, 28, 1), n_class)\nC_gan = define_gan(gen_model, discr_model)\nepochs = 100\nbatch_size = 64\nplot_freq = 10\ntrain(dataset, C_gan, gen_model, discr_model, noise_dims, n_class, epochs, batch_size, plot_freq)","metadata":{"id":"cd8HcObHf0a-","execution":{"iopub.status.busy":"2022-01-18T12:21:10.651609Z","iopub.execute_input":"2022-01-18T12:21:10.651891Z","iopub.status.idle":"2022-01-18T13:15:34.027546Z","shell.execute_reply.started":"2022-01-18T12:21:10.651856Z","shell.execute_reply":"2022-01-18T13:15:34.026784Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import os\ngen_model.save(os.path.join('./', 'Conditional_GAN.h5'))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:18:51.606974Z","iopub.execute_input":"2022-01-18T13:18:51.607228Z","iopub.status.idle":"2022-01-18T13:18:51.642364Z","shell.execute_reply.started":"2022-01-18T13:18:51.607200Z","shell.execute_reply":"2022-01-18T13:18:51.641687Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nC_gan = load_model('Conditional_GAN.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:19:00.133676Z","iopub.execute_input":"2022-01-18T13:19:00.133988Z","iopub.status.idle":"2022-01-18T13:19:00.230806Z","shell.execute_reply.started":"2022-01-18T13:19:00.133950Z","shell.execute_reply":"2022-01-18T13:19:00.230088Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"n_sample = 16\nnoise_dims = 100\nnoise_input = np.random.randn(n_sample, noise_dims)\ndesired_label = np.random.randint(0, 10, (16, 1))\nprint(noise_input.shape)\nprint(desired_label.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:19:34.980977Z","iopub.execute_input":"2022-01-18T13:19:34.981231Z","iopub.status.idle":"2022-01-18T13:19:34.987140Z","shell.execute_reply.started":"2022-01-18T13:19:34.981204Z","shell.execute_reply":"2022-01-18T13:19:34.986279Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"gen_imgs = C_gan.predict([noise_input, desired_label])","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:19:40.276887Z","iopub.execute_input":"2022-01-18T13:19:40.277562Z","iopub.status.idle":"2022-01-18T13:19:40.441392Z","shell.execute_reply.started":"2022-01-18T13:19:40.277528Z","shell.execute_reply":"2022-01-18T13:19:40.440639Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (3, 3))\nfor index, image in enumerate(gen_imgs):\n    ax = fig.add_subplot(4, 4, index + 1)\n    plt.imshow(image, cmap = 'gray_r')\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T13:31:08.446093Z","iopub.execute_input":"2022-01-18T13:31:08.446339Z","iopub.status.idle":"2022-01-18T13:31:08.922335Z","shell.execute_reply.started":"2022-01-18T13:31:08.446312Z","shell.execute_reply":"2022-01-18T13:31:08.921580Z"},"trusted":true},"execution_count":40,"outputs":[]}]}